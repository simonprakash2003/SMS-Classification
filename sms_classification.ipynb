{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4efb02a0-7f5f-4ef7-93c0-2e0f0c80c1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\simon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c60dfae-eb03-47d1-ad78-441ce20af390",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('spam.csv',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efed0adf-5fa6-4d5c-a9f0-cf174ac5d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[['v2','v1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd3c0df-ed21-4d32-90a6-b8a976cbdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.rename(columns={'v2':'message','v1':'labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fa99d86-f6e2-453f-bd2a-d16db3b3876f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "message    0\n",
       "labels     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fcde13f-3d7b-4c80-8b58-ec2c74a0e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573259ab-225a-417b-9de4-11c1c3885c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num_character']=data['message'].apply(len)\n",
    "data['num_words']=data['message'].apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "data['num_sentence']=data['message'].apply(lambda x:len(nltk.sent_tokenize(x)))\n",
    "data['labels']=data.labels.map({'ham':0,'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864e004-e140-40d4-9db9-edde09b80eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59dd080c-2f5e-4326-b292-0dc4f351b5ee",
   "metadata": {},
   "source": [
    "**preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adafddbc-17a2-4e4a-852b-1326e084ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORD=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b6f98d-1ba4-4aca-94af-80d2bed10089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  text=text.lower()\n",
    "  text=re.sub('\\W',\" \",text)\n",
    "  text=re.sub('\\d+',\" \",text)\n",
    "  text=re.sub(\"\\s+\",\" \",text)\n",
    "  text=\" \".join(words for words in text.split() if words not in STOPWORD)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44857b7e-cf99-42da-89f8-8a81a92b5b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>labels</th>\n",
       "      <th>num_character</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  labels  num_character  \\\n",
       "0  Go until jurong point, crazy.. Available only ...       0            111   \n",
       "1                      Ok lar... Joking wif u oni...       0             29   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...       1            155   \n",
       "3  U dun say so early hor... U c already then say...       0             49   \n",
       "4  Nah I don't think he goes to usf, he lives aro...       0             61   \n",
       "\n",
       "   num_words  num_sentence                                         clean_text  \n",
       "0         24             2  go jurong point crazy available bugis n great ...  \n",
       "1          8             2                            ok lar joking wif u oni  \n",
       "2         37             2  free entry wkly comp win fa cup final tkts st ...  \n",
       "3         13             1                u dun say early hor u c already say  \n",
       "4         15             1             nah think goes usf lives around though  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_text']=data['message'].apply(clean_text)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9212fb7c-2a5d-4bcd-8d90-589a65556d55",
   "metadata": {},
   "source": [
    "**split the input**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1157f4-77a8-422e-8905-b6a229a0e823",
   "metadata": {},
   "source": [
    "**model bulid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54c4dbb3-e151-49f1-97a4-14e11b39ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer(max_features=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e4d33c1-3693-4a80-87c8-0948e1313988",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tfidf.fit_transform(data['clean_text']).toarray()\n",
    "y=data['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef5a5523-5a2f-4570-9cab-99212df90199",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44fe3743-7e3b-4029-98a8-93a1adfdfdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50b4b055-c5d6-44f2-a538-c8d5d219dcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb=GaussianNB()\n",
    "mnb=MultinomialNB()\n",
    "bnb=BernoulliNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c573bd10-265c-4678-8ad5-46d4f3791e58",
   "metadata": {},
   "source": [
    "**Finding the best model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c70e2ad1-de21-4df5-8c14-cdcdff046693",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=[gnb,mnb,bnb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "264b6526-c612-4c94-91ca-baac8a4f1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model={}\n",
    "for i in model:\n",
    "    i.fit(X_train,y_train)\n",
    "    y_pred=i.predict(X_test)\n",
    "    ac=accuracy_score(y_test,y_pred)\n",
    "    cm=confusion_matrix(y_test,y_pred)\n",
    "    ps=precision_score(y_test,y_pred)\n",
    "    best_model[i]=[ac,ps]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33b2ee50-2db6-46cf-9a34-918da719c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=max(best_model, key= lambda x: best_model[x]) #which model is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a693d5ce-1212-465f-8401-e641d0ef25f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tfidf,open('vectorizer.pkl','wb'))\n",
    "pickle.dump(max(best_model, key= lambda x: best_model[x]),open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be97148a-ad41-4544-afd0-849756951bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the sms: Yay! Itâ€™s another Two for Tuesday. Order a box of candy today and get another one FREE. Hurry now and visit chocolates.com to order. Valid for orders above $20.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\\****----->Spam<------*****\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_sms=input(\"Enter the sms:\")\n",
    "\n",
    "transformed_sms=clean_text(input_sms)\n",
    "\n",
    "vector_input=tfidf.transform([transformed_sms])\n",
    "\n",
    "result=model .predict(vector_input)\n",
    "\n",
    "if result ==1:\n",
    "    print(\"\\n\\n\\n\\****----->Spam<------*****\\n\\n\\n\")\n",
    "else:\n",
    "    print(\"\\n\\n\\n****----->Not Spam<------*****\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f3a2f-c094-4496-9171-27b40f2b2193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a42bd72-3425-4c0b-8aa6-72645a8fda78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
